{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Photon Flux Estimation Demo\n",
    "\n",
    "This notebook demonstrates how to use the photon-flux-estimation package to analyze two-photon imaging data from the DANDI archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from dandi.dandiapi import DandiAPIClient\n",
    "from pynwb import NWBHDF5IO\n",
    "import h5py\n",
    "import fsspec\n",
    "from fsspec.implementations.cached import CachingFileSystem\n",
    "import pathlib\n",
    "\n",
    "from photon_flux_estimation import PhotonFluxAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data from DANDI\n",
    "\n",
    "We'll use the MICRONS dataset (000402) from the DANDI archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set up DANDI client and get dataset URLs\n",
    "dandiset_id = \"000402\"  # MICRONS dataset\n",
    "\n",
    "with DandiAPIClient() as client:\n",
    "    assets = client.get_dandiset(dandiset_id).get_assets()\n",
    "    s3_urls = [x.get_content_url(follow_redirects=1, strip_query=True) for x in assets]\n",
    "\n",
    "# Create a caching scheme for DANDI downloads\n",
    "cache_path = pathlib.Path('./cache')\n",
    "cache_path.mkdir(parents=True, exist_ok=True)\n",
    "fs = CachingFileSystem(fs=fsspec.filesystem(\"http\"), cache_storage=str(cache_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process and Analyze Data\n",
    "\n",
    "We'll analyze each two-photon series in the dataset using the PhotonFluxAnalyzer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create output directory for figures\n",
    "figure_path = pathlib.Path('./figures')\n",
    "figure_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for url in s3_urls:\n",
    "    # Open the file\n",
    "    with fs.open(url, \"rb\") as f:\n",
    "        with h5py.File(f) as file:\n",
    "            with NWBHDF5IO(file=file, load_namespaces=True) as io:\n",
    "                # Get all two-photon series objects\n",
    "                collection = (\n",
    "                    _ for _ in io.read().objects.values() \n",
    "                    if isinstance(_, pynwb.ophys.TwoPhotonSeries)\n",
    "                )\n",
    "\n",
    "                for count, two_photon_series in enumerate(collection):\n",
    "                    # Extract a portion of the data (frames 250-750, removing edge artifacts)\n",
    "                    scan = two_photon_series.data[250:750, 4:-4, 4:-4]\n",
    "                    scan = scan.transpose(0, 2, 1)\n",
    "                    \n",
    "                    try:\n",
    "                        # Create analyzer and compute sensitivity\n",
    "                        analyzer = PhotonFluxAnalyzer(scan.transpose(1, 2, 0))\n",
    "                        results = analyzer.compute_sensitivity()\n",
    "                        \n",
    "                        print(f'Processing {url.split(\"/\")[-1]} series {count}')\n",
    "                        print(f'Quantal size: {results[\"sensitivity\"]:.2f}')\n",
    "                        print(f'Zero level: {results[\"zero_level\"]:.2f}\\n')\n",
    "                        \n",
    "                        # Compute photon flux movie\n",
    "                        photon_flux = analyzer.compute_photon_flux()\n",
    "                        \n",
    "                        # Generate and save analysis figure\n",
    "                        title = f\"NWB-id:{two_photon_series.get_ancestor().identifier}\\n{two_photon_series.get_ancestor().session_id}\"\n",
    "                        save_path = figure_path / f\"{url.split('/')[-1]}-{count:03}.png\"\n",
    "                        analyzer.plot_analysis(title=title, save_path=save_path)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f'Error processing series {count}: {e}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting the Results\n",
    "\n",
    "For each two-photon series, the analyzer generates a figure with four panels:\n",
    "\n",
    "1. **Average Intensity**: Shows the mean intensity across all frames, providing a baseline view of the imaging field.\n",
    "\n",
    "2. **Photon Transfer Curve**: Plots intensity vs variance to estimate sensitivity. The slope of this curve gives us the photon sensitivity (gain) of the system.\n",
    "\n",
    "3. **Coefficient of Variation**: Visualizes the noise characteristics across the field of view. Areas with CV â‰ˆ 1 indicate shot-noise limited detection.\n",
    "\n",
    "4. **Photon Flux**: Shows estimated photons per pixel per frame after correcting for the system's sensitivity and zero level.\n",
    "\n",
    "The sensitivity value (gain) represents how many intensity units correspond to one photon. The zero level (offset) indicates the baseline intensity when no photons are detected.\n",
    "\n",
    "This analysis helps characterize the imaging system's performance and provides calibrated photon flux estimates from raw intensity measurements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
